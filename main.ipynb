{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "import os\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import cv2\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import StreamingResponse\n",
    "from io import BytesIO\n",
    "import uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize FastAPI app\n",
    "\n",
    "app = FastAPI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_DIR = os.path.abspath(\"templates\")  \n",
    "TEMPLATES = {\n",
    "    \"apple\": [os.path.join(TEMPLATE_DIR, \"apple1.jpg\"), os.path.join(TEMPLATE_DIR, \"apple2.jpg\")],\n",
    "    \"banana\": [os.path.join(TEMPLATE_DIR, \"banana1.jpg\"), os.path.join(TEMPLATE_DIR, \"banana2.jpg\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Missing template: /Users/user/Documents/GitHub/image-detection-app/templates/apple1.jpg\n",
      "‚ö†Ô∏è Missing template: /Users/user/Documents/GitHub/image-detection-app/templates/apple2.jpg\n",
      "‚ö†Ô∏è Missing template: /Users/user/Documents/GitHub/image-detection-app/templates/banana1.jpg\n",
      "‚ö†Ô∏è Missing template: /Users/user/Documents/GitHub/image-detection-app/templates/banana2.jpg\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è DEBUG: Check if template images exist\n",
    "for fruit, template_list in TEMPLATES.items():\n",
    "    for template in template_list:\n",
    "        if not os.path.exists(template):\n",
    "            print(f\"‚ö†Ô∏è Missing template: {template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_fruits_color(image: np.ndarray):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apple (Red)\n",
    "    lower_red1, upper_red1 = np.array([0, 100, 100]), np.array([10, 255, 255])\n",
    "    lower_red2, upper_red2 = np.array([160, 100, 100]), np.array([180, 255, 255])\n",
    "    mask_apples = cv2.inRange(hsv, lower_red1, upper_red1) + cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "\n",
    "    # Banana (Yellow)\n",
    "    lower_yellow, upper_yellow = np.array([20, 100, 100]), np.array([35, 255, 255])\n",
    "    mask_bananas = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_apples = cv2.morphologyEx(mask_apples, cv2.MORPH_OPEN, kernel)\n",
    "    mask_bananas = cv2.morphologyEx(mask_bananas, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    contours_apples, _ = cv2.findContours(mask_apples, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_bananas, _ = cv2.findContours(mask_bananas, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    apple_count = sum(1 for c in contours_apples if cv2.contourArea(c) > 1000)\n",
    "    banana_count = sum(1 for c in contours_bananas if cv2.contourArea(c) > 1000)\n",
    "\n",
    "    return image, {\"apple\": apple_count, \"banana\": banana_count}\n",
    "\n",
    "\n",
    "def detect_fruits_template(image: np.ndarray, templates: dict):\n",
    "    detected_image = image.copy()\n",
    "    apple_count, banana_count = 0, 0\n",
    "\n",
    "    # Loop through each fruit type and its templates\n",
    "    for fruit, template_list in templates.items():\n",
    "        for template_path in template_list:\n",
    "            if not os.path.exists(template_path):\n",
    "                print(f\"‚ö†Ô∏è Template missing: {template_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load the template image in grayscale\n",
    "            template_img = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if template_img is None:\n",
    "                print(f\"‚ùå Could not read {template_path}\")\n",
    "                continue\n",
    "\n",
    "            # Resize the template at different scales\n",
    "            for scale in np.linspace(0.8, 1.2, 5):\n",
    "                resized_template = cv2.resize(template_img, None, fx=scale, fy=scale)\n",
    "\n",
    "                # Perform template matching\n",
    "                res = cv2.matchTemplate(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), resized_template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "                # Set threshold for detection confidence\n",
    "                threshold = 0.7\n",
    "                loc = np.where(res >= threshold)\n",
    "\n",
    "                # Loop through all detected locations\n",
    "                for pt in zip(*loc[::-1]):  # loc gives coordinates in reversed order\n",
    "                    # Draw a bounding box around the detected fruit\n",
    "                    top_left = pt\n",
    "                    bottom_right = (pt[0] + resized_template.shape[1], pt[1] + resized_template.shape[0])\n",
    "                    cv2.rectangle(detected_image, top_left, bottom_right, (0, 255, 0), 3)\n",
    "\n",
    "                    # Add label with the name of the fruit (e.g., \"Apple\" or \"Banana\")\n",
    "                    label = f\"{fruit.capitalize()}\"\n",
    "                    label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                    label_x = top_left[0]\n",
    "                    label_y = top_left[1] - 10\n",
    "\n",
    "                    # Draw the label background (white rectangle behind the label)\n",
    "                    cv2.rectangle(detected_image, (label_x, label_y - label_size[1]), \n",
    "                                  (label_x + label_size[0], label_y + 5), (0, 255, 0), -1)\n",
    "\n",
    "                    # Draw the label text in white\n",
    "                    cv2.putText(detected_image, label, (label_x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "                    # Count the detected fruits\n",
    "                    if fruit == \"apple\":\n",
    "                        apple_count += 1\n",
    "                    elif fruit == \"banana\":\n",
    "                        banana_count += 1\n",
    "\n",
    "    return detected_image, {\"apple\": apple_count, \"banana\": banana_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoint to upload images and detect if they are apples or not \n",
    "@app.post(\"/detect_fruits\")\n",
    "async def detect_fruits(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        # Read image file\n",
    "        image_bytes = await file.read()\n",
    "        \n",
    "        # Convert to NumPy array\n",
    "        image_array = np.frombuffer(image_bytes, np.uint8)\n",
    "        \n",
    "        # Decode image\n",
    "        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if image is None:\n",
    "            print(\"Error: Could not decode image\")\n",
    "            return {\"error\": \"Invalid image file\"}\n",
    "\n",
    "        # Set up template paths (these should be real paths to template images)\n",
    "        templates = {\n",
    "            \"apple\": [\"apple_template1.jpg\", \"apple_template2.jpg\"],\n",
    "            \"banana\": [\"banana_template1.jpg\", \"banana_template2.jpg\"]\n",
    "        }\n",
    "\n",
    "        # Perform fruit detection using both methods\n",
    "        _, fruit_counts_color = detect_fruits_color(image)\n",
    "        image_template, fruit_counts_template = detect_fruits_template(image, templates)\n",
    "\n",
    "        # Combine the results (just summing counts for apples and bananas)\n",
    "        total_counts = {\n",
    "            \"apple\": fruit_counts_color[\"apple\"] + fruit_counts_template[\"apple\"],\n",
    "            \"banana\": fruit_counts_color[\"banana\"] + fruit_counts_template[\"banana\"]\n",
    "        }\n",
    "\n",
    "        # Encode image with bounding boxes\n",
    "        _, encoded_image = cv2.imencode(\".jpg\", image_template)\n",
    "        \n",
    "        # Return the image with bounding boxes as a response\n",
    "        return {\n",
    "            \"apple_count\": total_counts[\"apple\"],\n",
    "            \"banana_count\": total_counts[\"banana\"],\n",
    "            \"image\": StreamingResponse(BytesIO(encoded_image.tobytes()), media_type=\"image/jpeg\")\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [26475]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:53655 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:53655 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "‚ö†Ô∏è Template missing: apple_template1.jpg\n",
      "‚ö†Ô∏è Template missing: apple_template2.jpg\n",
      "‚ö†Ô∏è Template missing: banana_template1.jpg\n",
      "‚ö†Ô∏è Template missing: banana_template2.jpg\n",
      "INFO:     127.0.0.1:53658 - \"POST /detect_fruits HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/encoders.py\", line 324, in jsonable_encoder\n",
      "    data = dict(obj)\n",
      "           ^^^^^^^^^\n",
      "TypeError: 'async_generator' object is not iterable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/encoders.py\", line 329, in jsonable_encoder\n",
      "    data = vars(obj)\n",
      "           ^^^^^^^^^\n",
      "TypeError: vars() argument must have __dict__ attribute\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/applications.py\", line 112, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/routing.py\", line 715, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/routing.py\", line 735, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/starlette/routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/routing.py\", line 327, in app\n",
      "    content = await serialize_response(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/routing.py\", line 201, in serialize_response\n",
      "    return jsonable_encoder(response_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/encoders.py\", line 289, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "                    ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/encoders.py\", line 333, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/encoders.py\", line 289, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "                    ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/fastapi/encoders.py\", line 332, in jsonable_encoder\n",
      "    raise ValueError(errors) from e\n",
      "ValueError: [TypeError(\"'async_generator' object is not iterable\"), TypeError('vars() argument must have __dict__ attribute')]\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [26475]\n"
     ]
    }
   ],
   "source": [
    "# Runnin the API server\n",
    "nest_asyncio.apply()  # Allows FastAPI to run inside Jupyter\n",
    "\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references for the code used: \n",
    "National Film Board of Canada. (2017, April 12). Trick or Treaty? - Alanis Obomsawin (2014) [HD, 52 min] [Video]. YouTube. https://www.youtube.com/watch?v=tc5-wp7D9ko \n",
    "most of image detection video served as references point for my code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
